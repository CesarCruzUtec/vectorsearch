{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openai import OpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "from rich import print, inspect\n",
    "\n",
    "relevant_columns = {\n",
    "    \"_SkuId (Not changeable)\": (\"ID SKU\", \"id_sku\"),\n",
    "    \"_SkuName\": (\"Nombre\", \"nombre\"),\n",
    "    \"_ProductShortDescription\": (\"Descripción Corta\", \"descripcion_corta\"),\n",
    "    \"_ProductDescription\": (\"Descripción Larga\", \"descripcion_larga\"),\n",
    "    \"_Keywords\": (\"Palabras Clave\", \"palabras_clave\"),\n",
    "    \"_MetaTagDescription\": (\"Descripción Meta\", \"descripcion_meta\"),\n",
    "    \"_DepartamentName\": (\"Departamento\", \"departamento\"),\n",
    "    \"_CategoryName\": (\"Categoría\", \"categoria\"),\n",
    "    \"_Brand\": (\"Marca\", \"marca\"),\n",
    "}\n",
    "\n",
    "index_file = \"embeddings.faiss\"\n",
    "index = None\n",
    "ids_file = \"ids_faiss.npy\"\n",
    "ids_faiss = None\n",
    "data = None\n",
    "\n",
    "\n",
    "def load_env():\n",
    "    # Load the .env file\n",
    "    env_file_path = \".env\"\n",
    "    openai_api_key = None\n",
    "\n",
    "    if os.path.exists(env_file_path):\n",
    "        with open(env_file_path) as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"OPENAI_API_KEY\"):\n",
    "                    openai_api_key = line.strip().split(\"=\")[1]\n",
    "                    break\n",
    "\n",
    "    if openai_api_key:\n",
    "        print(\"OpenAI API Key loaded successfully.\")\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    else:\n",
    "        print(\"OpenAI API Key not found.\")\n",
    "\n",
    "\n",
    "load_env()\n",
    "\n",
    "\n",
    "def load_excel(path):\n",
    "    df = pd.read_excel(path, usecols=relevant_columns.keys(), dtype=str)\n",
    "    df.fillna(\"No Info\", inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_file_from_excel(data, samples=1000, output_file=\"catalogo.xlsx\"):\n",
    "    data.sample(samples).to_excel(output_file, index=False)\n",
    "    print(f\"File {output_file} created successfully.\")\n",
    "\n",
    "\n",
    "def get_string_from_row(row, verbose=False):\n",
    "    final_string = []\n",
    "    for column, value in relevant_columns.items():\n",
    "        if hasattr(row[column], \"values\"):\n",
    "            row_value = row[column].values[0]\n",
    "        else:\n",
    "            row_value = row[column]\n",
    "\n",
    "        if column == \"_SkuId (Not changeable)\":\n",
    "            continue\n",
    "\n",
    "        if column == \"_ProductDescription\" or column == \"_MetaTagDescription\":\n",
    "            row_value = BeautifulSoup(row_value, \"html.parser\").get_text(separator=\", \")\n",
    "\n",
    "        if column == \"_Keywords\":\n",
    "            keywords = row_value.split(\",\")\n",
    "            keywords = [keyword.strip() for keyword in keywords]\n",
    "            row_value = \", \".join(\n",
    "                [keyword for keyword in keywords if not keyword.isdigit()]\n",
    "            )\n",
    "\n",
    "        if row_value != \"No Info\":\n",
    "            final_string.append(f\"{value[0]}: {row_value}\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{value[0]}: {row_value}\")\n",
    "\n",
    "    return \"; \".join(final_string)\n",
    "\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    embedding = response.data[0].embedding\n",
    "    tokens = response.usage.total_tokens\n",
    "    return embedding, tokens\n",
    "\n",
    "\n",
    "def get_tokens_length(text, encoding=\"cl100k_base\"):\n",
    "    encoding = tiktoken.get_encoding(encoding)\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def create_batch_files(data, max_rows_per_file=500, output_file_prefix=\"batch\"):\n",
    "    total_tokens = 0\n",
    "    file_count = 0\n",
    "    row_count = 0\n",
    "\n",
    "    f = None\n",
    "    for idx, row in data.iterrows():\n",
    "        if row_count % max_rows_per_file == 0:\n",
    "            if row_count > 0:\n",
    "                f.close()\n",
    "            file_count += 1\n",
    "            output_file = f\"{output_file_prefix}_{file_count}.jsonl\"\n",
    "            f = open(output_file, \"w\")\n",
    "\n",
    "        string_row = get_string_from_row(row)\n",
    "        tokens = get_tokens_length(string_row)\n",
    "        total_tokens += tokens\n",
    "\n",
    "        payload = {\n",
    "            \"custom_id\": row[\"_SkuId (Not changeable)\"],\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/embeddings\",\n",
    "            \"body\": {\n",
    "                \"model\": \"text-embedding-3-small\",\n",
    "                \"input\": string_row,\n",
    "            },\n",
    "        }\n",
    "        f.write(json.dumps(payload, ensure_ascii=True) + \"\\n\")\n",
    "        row_count += 1\n",
    "\n",
    "    f.close()\n",
    "    print(\"Batch files created successfully.\")\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print(f\"Promedio de tokens: {total_tokens / len(data):.2f}\")\n",
    "\n",
    "\n",
    "def upload_batch_file(batch_file=\"batch.jsonl\", verbose=False):\n",
    "    batch_input_file = client.files.create(file=open(batch_file, \"rb\"), purpose=\"batch\")\n",
    "    print(\"Batch file uploaded successfully.\")\n",
    "    if verbose:\n",
    "        print(batch_input_file)\n",
    "    return batch_input_file\n",
    "\n",
    "\n",
    "def create_batch_online(batch_id, description=\"Normal batch\", verbose=False):\n",
    "    \"\"\"\n",
    "    Create a batch with the given batch_id and description.\n",
    "    Max requests: 50 000\n",
    "    Max file size: 200MB\n",
    "    \"\"\"\n",
    "    batch_metadata = client.batches.create(\n",
    "        input_file_id=batch_id,\n",
    "        endpoint=\"/v1/embeddings\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\"description\": description},\n",
    "    )\n",
    "    print(\"Batch created successfully.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(batch_metadata.model_dump())\n",
    "\n",
    "    return batch_metadata\n",
    "\n",
    "\n",
    "def check_status_batch(batch_id):\n",
    "    batch_status = client.batches.retrieve(batch_id)\n",
    "    return batch_status\n",
    "\n",
    "\n",
    "def get_results(batch_id):\n",
    "    batch_status = check_status_batch(batch_id)\n",
    "    if batch_status.status != \"completed\":\n",
    "        print(\"Batch not completed yet.\")\n",
    "        return None\n",
    "\n",
    "    output_file_id = batch_status.output_file_id\n",
    "    results = client.files.content(output_file_id)\n",
    "\n",
    "    file_name = f\"results_{batch_id}.jsonl\"\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(results.text)\n",
    "\n",
    "\n",
    "def read_large_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            yield line\n",
    "\n",
    "\n",
    "def save_embeddings(file_paths):\n",
    "    ids_faiss = []\n",
    "    embeddings = []\n",
    "    vector_dim = 0\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        for line in read_large_file(file_path):\n",
    "            data = json.loads(line)\n",
    "\n",
    "            ids_faiss.append(data[\"custom_id\"])\n",
    "            embedding = data[\"response\"][\"body\"][\"data\"][0][\"embedding\"]\n",
    "            vector_dim = len(embedding)\n",
    "            embeddings.append(np.array(embedding, dtype=np.float32))\n",
    "\n",
    "    index = faiss.IndexFlatL2(vector_dim)\n",
    "    if embeddings:\n",
    "        embeddings_matrix = np.vstack(embeddings)\n",
    "        index.add(embeddings_matrix)\n",
    "\n",
    "    faiss.write_index(index, index_file)\n",
    "    np.save(ids_file, np.array(ids_faiss))\n",
    "\n",
    "    print(\"Embeddings saved successfully.\")\n",
    "    return index, ids_faiss\n",
    "\n",
    "\n",
    "def cargar_faiss_desde_disco(input_file=None):\n",
    "    if os.path.exists(index_file) and os.path.exists(ids_file):\n",
    "        index = faiss.read_index(index_file)\n",
    "        ids_faiss = np.load(ids_file).tolist()\n",
    "        print(\"Índice FAISS cargado desde disco.\")\n",
    "        return index, ids_faiss\n",
    "    else:\n",
    "        print(\"No se encontró un índice en disco. Creando uno nuevo.\")\n",
    "        if not input_file:\n",
    "            print(\"No se especificó una lista de embeddings para cargar.\")\n",
    "            return None, None\n",
    "        return save_embeddings(input_file)\n",
    "\n",
    "\n",
    "def buscar_faiss(query, top_k=5):\n",
    "    query_embedding, tokens = get_embedding(query)\n",
    "    price_tokens_1M = 0.02 # 0.02 dolares por cada 1M de tokens\n",
    "    price = price_tokens_1M * tokens / 1_000_000\n",
    "    print(f\"Tokens: {tokens}, Costo: ${price:.10f}\")\n",
    "\n",
    "    query_embedding = np.array(query_embedding, dtype=np.float32).reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    results = [(ids_faiss[idx], dist) for idx, dist in zip(indices[0], distances[0])]\n",
    "    for sku_id, dist in results:\n",
    "        row = data[data[\"_SkuId (Not changeable)\"] == sku_id]\n",
    "        print(f\"Distancia: {dist:.2f}\")\n",
    "        out_str = \"\"\n",
    "        for column, value in relevant_columns.items():\n",
    "            out_str += f\"{value[0]}: {row[column].values[0]}\\n\"\n",
    "        print(out_str)\n",
    "\n",
    "# index, ids_faiss = cargar_faiss_desde_disco(\"results.jsonl\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_excel(\"./text_search/wong_catalogo_prueba.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file_from_excel(data, samples=1000, output_file=\"./text_search/wong_catalogo_1000.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_excel(\"./text_search/wong_catalogo_1000.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row = data.sample(1)\n",
    "string_row = get_string_from_row(random_row, verbose=True)\n",
    "print(string_row)\n",
    "tokens = get_tokens_length(string_row)\n",
    "print(f\"Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batch_files(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id1 = upload_batch_file(\"batch_1.jsonl\", verbose=True)\n",
    "batch_id2 = upload_batch_file(\"batch_2.jsonl\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_online_id1 = create_batch_online(batch_id1.id, description=\"Batch 1\")\n",
    "batch_online_id2 = create_batch_online(batch_id2.id, description=\"Batch 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status1 = check_status_batch(batch_online_id1.id)\n",
    "print(status1.model_dump())\n",
    "status2 = check_status_batch(batch_online_id2.id)\n",
    "print(status2.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(batch_online_id1.id)\n",
    "get_results(batch_online_id2.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    f\"results_{batch_online_id1.id}.jsonl\",\n",
    "    f\"results_{batch_online_id2.id}.jsonl\",\n",
    "]\n",
    "index, ids_faiss = save_embeddings(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, ids_faiss = cargar_faiss_desde_disco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file size in bytes\n",
    "file_size = os.path.getsize(\"embeddings.faiss\")\n",
    "print(f\"File size: {file_size / 1024 / 1024:.2f} MB\")\n",
    "file_size = os.path.getsize(\"ids_faiss.npy\")\n",
    "print(f\"File size: {file_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buscar_faiss(\"Productos para san valentin\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_row = data.sample(1)\n",
    "\n",
    "result_iter = read_large_file(\"results.jsonl\")\n",
    "first_result = json.loads(next(result_iter))\n",
    "first_result[\"response\"][\"body\"][\"data\"][0][\"embedding\"] = \"EMBEDDING\"\n",
    "\n",
    "print(first_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
